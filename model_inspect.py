from diffusers import AutoencoderKL
import torch

# Load the pre-trained model
model = AutoencoderKL.from_pretrained("runwayml/stable-diffusion-v1-5", subfolder="vae", torch_dtype=torch.float32).to("cuda")

# Print the model architecture
print(model)

# Print the shapes of model parameters
for name, param in model.named_parameters():
    print(name, param.shape)

output:
AutoencoderKL(
  (encoder): Encoder(
    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (down_blocks): ModuleList(
      (0): DownEncoderBlock2D(
        (resnets): ModuleList(
          (0-1): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
        (downsamplers): ModuleList(
          (0): Downsample2D(
            (conv): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(2, 2))
          )
        )
      )
      (1): DownEncoderBlock2D(
        (resnets): ModuleList(
          (0): ResnetBlock2D(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): LoRACompatibleConv(128, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock2D(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
        (downsamplers): ModuleList(
          (0): Downsample2D(
            (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(2, 2))
          )
        )
      )
      (2): DownEncoderBlock2D(
        (resnets): ModuleList(
          (0): ResnetBlock2D(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): LoRACompatibleConv(256, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock2D(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
        (downsamplers): ModuleList(
          (0): Downsample2D(
            (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(2, 2))
          )
        )
      )
      (3): DownEncoderBlock2D(
        (resnets): ModuleList(
          (0-1): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
      )
    )
    (mid_block): UNetMidBlock2D(
      (attentions): ModuleList(
        (0): Attention(
          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)
          (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)
          (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)
          (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)
          (to_out): ModuleList(
            (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)
            (1): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (resnets): ModuleList(
        (0-1): 2 x ResnetBlock2D(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (nonlinearity): SiLU()
        )
      )
    )
    (conv_norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)
    (conv_act): SiLU()
    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (decoder): Decoder(
    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (up_blocks): ModuleList(
      (0-1): 2 x UpDecoderBlock2D(
        (resnets): ModuleList(
          (0-2): 3 x ResnetBlock2D(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
        (upsamplers): ModuleList(
          (0): Upsample2D(
            (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (2): UpDecoderBlock2D(
        (resnets): ModuleList(
          (0): ResnetBlock2D(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): LoRACompatibleConv(512, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (1-2): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
        (upsamplers): ModuleList(
          (0): Upsample2D(
            (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
      )
      (3): UpDecoderBlock2D(
        (resnets): ModuleList(
          (0): ResnetBlock2D(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
            (conv_shortcut): LoRACompatibleConv(256, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (1-2): 2 x ResnetBlock2D(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nonlinearity): SiLU()
          )
        )
      )
    )
    (mid_block): UNetMidBlock2D(
      (attentions): ModuleList(
        (0): Attention(
          (group_norm): GroupNorm(32, 512, eps=1e-06, affine=True)
          (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)
          (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)
          (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)
          (to_out): ModuleList(
            (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)
            (1): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (resnets): ModuleList(
        (0-1): 2 x ResnetBlock2D(
          (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
          (dropout): Dropout(p=0.0, inplace=False)
          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (nonlinearity): SiLU()
        )
      )
    )
    (conv_norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)
    (conv_act): SiLU()
    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))
  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))
)
encoder.conv_in.weight torch.Size([128, 3, 3, 3])
encoder.conv_in.bias torch.Size([128])
encoder.down_blocks.0.resnets.0.norm1.weight torch.Size([128])
encoder.down_blocks.0.resnets.0.norm1.bias torch.Size([128])
encoder.down_blocks.0.resnets.0.conv1.weight torch.Size([128, 128, 3, 3])
encoder.down_blocks.0.resnets.0.conv1.bias torch.Size([128])
encoder.down_blocks.0.resnets.0.norm2.weight torch.Size([128])
encoder.down_blocks.0.resnets.0.norm2.bias torch.Size([128])
encoder.down_blocks.0.resnets.0.conv2.weight torch.Size([128, 128, 3, 3])
encoder.down_blocks.0.resnets.0.conv2.bias torch.Size([128])
encoder.down_blocks.0.resnets.1.norm1.weight torch.Size([128])
encoder.down_blocks.0.resnets.1.norm1.bias torch.Size([128])
encoder.down_blocks.0.resnets.1.conv1.weight torch.Size([128, 128, 3, 3])
encoder.down_blocks.0.resnets.1.conv1.bias torch.Size([128])
encoder.down_blocks.0.resnets.1.norm2.weight torch.Size([128])
encoder.down_blocks.0.resnets.1.norm2.bias torch.Size([128])
encoder.down_blocks.0.resnets.1.conv2.weight torch.Size([128, 128, 3, 3])
encoder.down_blocks.0.resnets.1.conv2.bias torch.Size([128])
encoder.down_blocks.0.downsamplers.0.conv.weight torch.Size([128, 128, 3, 3])
encoder.down_blocks.0.downsamplers.0.conv.bias torch.Size([128])
encoder.down_blocks.1.resnets.0.norm1.weight torch.Size([128])
encoder.down_blocks.1.resnets.0.norm1.bias torch.Size([128])
encoder.down_blocks.1.resnets.0.conv1.weight torch.Size([256, 128, 3, 3])
encoder.down_blocks.1.resnets.0.conv1.bias torch.Size([256])
encoder.down_blocks.1.resnets.0.norm2.weight torch.Size([256])
encoder.down_blocks.1.resnets.0.norm2.bias torch.Size([256])
encoder.down_blocks.1.resnets.0.conv2.weight torch.Size([256, 256, 3, 3])
encoder.down_blocks.1.resnets.0.conv2.bias torch.Size([256])
encoder.down_blocks.1.resnets.0.conv_shortcut.weight torch.Size([256, 128, 1, 1])
encoder.down_blocks.1.resnets.0.conv_shortcut.bias torch.Size([256])
encoder.down_blocks.1.resnets.1.norm1.weight torch.Size([256])
encoder.down_blocks.1.resnets.1.norm1.bias torch.Size([256])
encoder.down_blocks.1.resnets.1.conv1.weight torch.Size([256, 256, 3, 3])
encoder.down_blocks.1.resnets.1.conv1.bias torch.Size([256])
encoder.down_blocks.1.resnets.1.norm2.weight torch.Size([256])
encoder.down_blocks.1.resnets.1.norm2.bias torch.Size([256])
encoder.down_blocks.1.resnets.1.conv2.weight torch.Size([256, 256, 3, 3])
encoder.down_blocks.1.resnets.1.conv2.bias torch.Size([256])
encoder.down_blocks.1.downsamplers.0.conv.weight torch.Size([256, 256, 3, 3])
encoder.down_blocks.1.downsamplers.0.conv.bias torch.Size([256])
encoder.down_blocks.2.resnets.0.norm1.weight torch.Size([256])
encoder.down_blocks.2.resnets.0.norm1.bias torch.Size([256])
encoder.down_blocks.2.resnets.0.conv1.weight torch.Size([512, 256, 3, 3])
encoder.down_blocks.2.resnets.0.conv1.bias torch.Size([512])
encoder.down_blocks.2.resnets.0.norm2.weight torch.Size([512])
encoder.down_blocks.2.resnets.0.norm2.bias torch.Size([512])
encoder.down_blocks.2.resnets.0.conv2.weight torch.Size([512, 512, 3, 3])
encoder.down_blocks.2.resnets.0.conv2.bias torch.Size([512])
encoder.down_blocks.2.resnets.0.conv_shortcut.weight torch.Size([512, 256, 1, 1])
encoder.down_blocks.2.resnets.0.conv_shortcut.bias torch.Size([512])
encoder.down_blocks.2.resnets.1.norm1.weight torch.Size([512])
encoder.down_blocks.2.resnets.1.norm1.bias torch.Size([512])
encoder.down_blocks.2.resnets.1.conv1.weight torch.Size([512, 512, 3, 3])
encoder.down_blocks.2.resnets.1.conv1.bias torch.Size([512])
encoder.down_blocks.2.resnets.1.norm2.weight torch.Size([512])
encoder.down_blocks.2.resnets.1.norm2.bias torch.Size([512])
encoder.down_blocks.2.resnets.1.conv2.weight torch.Size([512, 512, 3, 3])
encoder.down_blocks.2.resnets.1.conv2.bias torch.Size([512])
encoder.down_blocks.2.downsamplers.0.conv.weight torch.Size([512, 512, 3, 3])
encoder.down_blocks.2.downsamplers.0.conv.bias torch.Size([512])
encoder.down_blocks.3.resnets.0.norm1.weight torch.Size([512])
encoder.down_blocks.3.resnets.0.norm1.bias torch.Size([512])
encoder.down_blocks.3.resnets.0.conv1.weight torch.Size([512, 512, 3, 3])
encoder.down_blocks.3.resnets.0.conv1.bias torch.Size([512])
encoder.down_blocks.3.resnets.0.norm2.weight torch.Size([512])
encoder.down_blocks.3.resnets.0.norm2.bias torch.Size([512])
encoder.down_blocks.3.resnets.0.conv2.weight torch.Size([512, 512, 3, 3])
encoder.down_blocks.3.resnets.0.conv2.bias torch.Size([512])
encoder.down_blocks.3.resnets.1.norm1.weight torch.Size([512])
encoder.down_blocks.3.resnets.1.norm1.bias torch.Size([512])
encoder.down_blocks.3.resnets.1.conv1.weight torch.Size([512, 512, 3, 3])
encoder.down_blocks.3.resnets.1.conv1.bias torch.Size([512])
encoder.down_blocks.3.resnets.1.norm2.weight torch.Size([512])
encoder.down_blocks.3.resnets.1.norm2.bias torch.Size([512])
encoder.down_blocks.3.resnets.1.conv2.weight torch.Size([512, 512, 3, 3])
encoder.down_blocks.3.resnets.1.conv2.bias torch.Size([512])
encoder.mid_block.attentions.0.group_norm.weight torch.Size([512])
encoder.mid_block.attentions.0.group_norm.bias torch.Size([512])
encoder.mid_block.attentions.0.to_q.weight torch.Size([512, 512])
encoder.mid_block.attentions.0.to_q.bias torch.Size([512])
encoder.mid_block.attentions.0.to_k.weight torch.Size([512, 512])
encoder.mid_block.attentions.0.to_k.bias torch.Size([512])
encoder.mid_block.attentions.0.to_v.weight torch.Size([512, 512])
encoder.mid_block.attentions.0.to_v.bias torch.Size([512])
encoder.mid_block.attentions.0.to_out.0.weight torch.Size([512, 512])
encoder.mid_block.attentions.0.to_out.0.bias torch.Size([512])
encoder.mid_block.resnets.0.norm1.weight torch.Size([512])
encoder.mid_block.resnets.0.norm1.bias torch.Size([512])
encoder.mid_block.resnets.0.conv1.weight torch.Size([512, 512, 3, 3])
encoder.mid_block.resnets.0.conv1.bias torch.Size([512])
encoder.mid_block.resnets.0.norm2.weight torch.Size([512])
encoder.mid_block.resnets.0.norm2.bias torch.Size([512])
encoder.mid_block.resnets.0.conv2.weight torch.Size([512, 512, 3, 3])
encoder.mid_block.resnets.0.conv2.bias torch.Size([512])
encoder.mid_block.resnets.1.norm1.weight torch.Size([512])
encoder.mid_block.resnets.1.norm1.bias torch.Size([512])
encoder.mid_block.resnets.1.conv1.weight torch.Size([512, 512, 3, 3])
encoder.mid_block.resnets.1.conv1.bias torch.Size([512])
encoder.mid_block.resnets.1.norm2.weight torch.Size([512])
encoder.mid_block.resnets.1.norm2.bias torch.Size([512])
encoder.mid_block.resnets.1.conv2.weight torch.Size([512, 512, 3, 3])
encoder.mid_block.resnets.1.conv2.bias torch.Size([512])
encoder.conv_norm_out.weight torch.Size([512])
encoder.conv_norm_out.bias torch.Size([512])
encoder.conv_out.weight torch.Size([8, 512, 3, 3])
encoder.conv_out.bias torch.Size([8])
decoder.conv_in.weight torch.Size([512, 4, 3, 3])
decoder.conv_in.bias torch.Size([512])
decoder.up_blocks.0.resnets.0.norm1.weight torch.Size([512])
decoder.up_blocks.0.resnets.0.norm1.bias torch.Size([512])
decoder.up_blocks.0.resnets.0.conv1.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.0.resnets.0.conv1.bias torch.Size([512])
decoder.up_blocks.0.resnets.0.norm2.weight torch.Size([512])
decoder.up_blocks.0.resnets.0.norm2.bias torch.Size([512])
decoder.up_blocks.0.resnets.0.conv2.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.0.resnets.0.conv2.bias torch.Size([512])
decoder.up_blocks.0.resnets.1.norm1.weight torch.Size([512])
decoder.up_blocks.0.resnets.1.norm1.bias torch.Size([512])
decoder.up_blocks.0.resnets.1.conv1.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.0.resnets.1.conv1.bias torch.Size([512])
decoder.up_blocks.0.resnets.1.norm2.weight torch.Size([512])
decoder.up_blocks.0.resnets.1.norm2.bias torch.Size([512])
decoder.up_blocks.0.resnets.1.conv2.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.0.resnets.1.conv2.bias torch.Size([512])
decoder.up_blocks.0.resnets.2.norm1.weight torch.Size([512])
decoder.up_blocks.0.resnets.2.norm1.bias torch.Size([512])
decoder.up_blocks.0.resnets.2.conv1.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.0.resnets.2.conv1.bias torch.Size([512])
decoder.up_blocks.0.resnets.2.norm2.weight torch.Size([512])
decoder.up_blocks.0.resnets.2.norm2.bias torch.Size([512])
decoder.up_blocks.0.resnets.2.conv2.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.0.resnets.2.conv2.bias torch.Size([512])
decoder.up_blocks.0.upsamplers.0.conv.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.0.upsamplers.0.conv.bias torch.Size([512])
decoder.up_blocks.1.resnets.0.norm1.weight torch.Size([512])
decoder.up_blocks.1.resnets.0.norm1.bias torch.Size([512])
decoder.up_blocks.1.resnets.0.conv1.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.1.resnets.0.conv1.bias torch.Size([512])
decoder.up_blocks.1.resnets.0.norm2.weight torch.Size([512])
decoder.up_blocks.1.resnets.0.norm2.bias torch.Size([512])
decoder.up_blocks.1.resnets.0.conv2.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.1.resnets.0.conv2.bias torch.Size([512])
decoder.up_blocks.1.resnets.1.norm1.weight torch.Size([512])
decoder.up_blocks.1.resnets.1.norm1.bias torch.Size([512])
decoder.up_blocks.1.resnets.1.conv1.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.1.resnets.1.conv1.bias torch.Size([512])
decoder.up_blocks.1.resnets.1.norm2.weight torch.Size([512])
decoder.up_blocks.1.resnets.1.norm2.bias torch.Size([512])
decoder.up_blocks.1.resnets.1.conv2.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.1.resnets.1.conv2.bias torch.Size([512])
decoder.up_blocks.1.resnets.2.norm1.weight torch.Size([512])
decoder.up_blocks.1.resnets.2.norm1.bias torch.Size([512])
decoder.up_blocks.1.resnets.2.conv1.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.1.resnets.2.conv1.bias torch.Size([512])
decoder.up_blocks.1.resnets.2.norm2.weight torch.Size([512])
decoder.up_blocks.1.resnets.2.norm2.bias torch.Size([512])
decoder.up_blocks.1.resnets.2.conv2.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.1.resnets.2.conv2.bias torch.Size([512])
decoder.up_blocks.1.upsamplers.0.conv.weight torch.Size([512, 512, 3, 3])
decoder.up_blocks.1.upsamplers.0.conv.bias torch.Size([512])
decoder.up_blocks.2.resnets.0.norm1.weight torch.Size([512])
decoder.up_blocks.2.resnets.0.norm1.bias torch.Size([512])
decoder.up_blocks.2.resnets.0.conv1.weight torch.Size([256, 512, 3, 3])
decoder.up_blocks.2.resnets.0.conv1.bias torch.Size([256])
decoder.up_blocks.2.resnets.0.norm2.weight torch.Size([256])
decoder.up_blocks.2.resnets.0.norm2.bias torch.Size([256])
decoder.up_blocks.2.resnets.0.conv2.weight torch.Size([256, 256, 3, 3])
decoder.up_blocks.2.resnets.0.conv2.bias torch.Size([256])
decoder.up_blocks.2.resnets.0.conv_shortcut.weight torch.Size([256, 512, 1, 1])
decoder.up_blocks.2.resnets.0.conv_shortcut.bias torch.Size([256])
decoder.up_blocks.2.resnets.1.norm1.weight torch.Size([256])
decoder.up_blocks.2.resnets.1.norm1.bias torch.Size([256])
decoder.up_blocks.2.resnets.1.conv1.weight torch.Size([256, 256, 3, 3])
decoder.up_blocks.2.resnets.1.conv1.bias torch.Size([256])
decoder.up_blocks.2.resnets.1.norm2.weight torch.Size([256])
decoder.up_blocks.2.resnets.1.norm2.bias torch.Size([256])
decoder.up_blocks.2.resnets.1.conv2.weight torch.Size([256, 256, 3, 3])
decoder.up_blocks.2.resnets.1.conv2.bias torch.Size([256])
decoder.up_blocks.2.resnets.2.norm1.weight torch.Size([256])
decoder.up_blocks.2.resnets.2.norm1.bias torch.Size([256])
decoder.up_blocks.2.resnets.2.conv1.weight torch.Size([256, 256, 3, 3])
decoder.up_blocks.2.resnets.2.conv1.bias torch.Size([256])
decoder.up_blocks.2.resnets.2.norm2.weight torch.Size([256])
decoder.up_blocks.2.resnets.2.norm2.bias torch.Size([256])
decoder.up_blocks.2.resnets.2.conv2.weight torch.Size([256, 256, 3, 3])
decoder.up_blocks.2.resnets.2.conv2.bias torch.Size([256])
decoder.up_blocks.2.upsamplers.0.conv.weight torch.Size([256, 256, 3, 3])
decoder.up_blocks.2.upsamplers.0.conv.bias torch.Size([256])
decoder.up_blocks.3.resnets.0.norm1.weight torch.Size([256])
decoder.up_blocks.3.resnets.0.norm1.bias torch.Size([256])
decoder.up_blocks.3.resnets.0.conv1.weight torch.Size([128, 256, 3, 3])
decoder.up_blocks.3.resnets.0.conv1.bias torch.Size([128])
decoder.up_blocks.3.resnets.0.norm2.weight torch.Size([128])
decoder.up_blocks.3.resnets.0.norm2.bias torch.Size([128])
decoder.up_blocks.3.resnets.0.conv2.weight torch.Size([128, 128, 3, 3])
decoder.up_blocks.3.resnets.0.conv2.bias torch.Size([128])
decoder.up_blocks.3.resnets.0.conv_shortcut.weight torch.Size([128, 256, 1, 1])
decoder.up_blocks.3.resnets.0.conv_shortcut.bias torch.Size([128])
decoder.up_blocks.3.resnets.1.norm1.weight torch.Size([128])
decoder.up_blocks.3.resnets.1.norm1.bias torch.Size([128])
decoder.up_blocks.3.resnets.1.conv1.weight torch.Size([128, 128, 3, 3])
decoder.up_blocks.3.resnets.1.conv1.bias torch.Size([128])
decoder.up_blocks.3.resnets.1.norm2.weight torch.Size([128])
decoder.up_blocks.3.resnets.1.norm2.bias torch.Size([128])
decoder.up_blocks.3.resnets.1.conv2.weight torch.Size([128, 128, 3, 3])
decoder.up_blocks.3.resnets.1.conv2.bias torch.Size([128])
decoder.up_blocks.3.resnets.2.norm1.weight torch.Size([128])
decoder.up_blocks.3.resnets.2.norm1.bias torch.Size([128])
decoder.up_blocks.3.resnets.2.conv1.weight torch.Size([128, 128, 3, 3])
decoder.up_blocks.3.resnets.2.conv1.bias torch.Size([128])
decoder.up_blocks.3.resnets.2.norm2.weight torch.Size([128])
decoder.up_blocks.3.resnets.2.norm2.bias torch.Size([128])
decoder.up_blocks.3.resnets.2.conv2.weight torch.Size([128, 128, 3, 3])
decoder.up_blocks.3.resnets.2.conv2.bias torch.Size([128])
decoder.mid_block.attentions.0.group_norm.weight torch.Size([512])
decoder.mid_block.attentions.0.group_norm.bias torch.Size([512])
decoder.mid_block.attentions.0.to_q.weight torch.Size([512, 512])
decoder.mid_block.attentions.0.to_q.bias torch.Size([512])
decoder.mid_block.attentions.0.to_k.weight torch.Size([512, 512])
decoder.mid_block.attentions.0.to_k.bias torch.Size([512])
decoder.mid_block.attentions.0.to_v.weight torch.Size([512, 512])
decoder.mid_block.attentions.0.to_v.bias torch.Size([512])
decoder.mid_block.attentions.0.to_out.0.weight torch.Size([512, 512])
decoder.mid_block.attentions.0.to_out.0.bias torch.Size([512])
decoder.mid_block.resnets.0.norm1.weight torch.Size([512])
decoder.mid_block.resnets.0.norm1.bias torch.Size([512])
decoder.mid_block.resnets.0.conv1.weight torch.Size([512, 512, 3, 3])
decoder.mid_block.resnets.0.conv1.bias torch.Size([512])
decoder.mid_block.resnets.0.norm2.weight torch.Size([512])
decoder.mid_block.resnets.0.norm2.bias torch.Size([512])
decoder.mid_block.resnets.0.conv2.weight torch.Size([512, 512, 3, 3])
decoder.mid_block.resnets.0.conv2.bias torch.Size([512])
decoder.mid_block.resnets.1.norm1.weight torch.Size([512])
decoder.mid_block.resnets.1.norm1.bias torch.Size([512])
decoder.mid_block.resnets.1.conv1.weight torch.Size([512, 512, 3, 3])
decoder.mid_block.resnets.1.conv1.bias torch.Size([512])
decoder.mid_block.resnets.1.norm2.weight torch.Size([512])
decoder.mid_block.resnets.1.norm2.bias torch.Size([512])
decoder.mid_block.resnets.1.conv2.weight torch.Size([512, 512, 3, 3])
decoder.mid_block.resnets.1.conv2.bias torch.Size([512])
decoder.conv_norm_out.weight torch.Size([128])
decoder.conv_norm_out.bias torch.Size([128])
decoder.conv_out.weight torch.Size([3, 128, 3, 3])
decoder.conv_out.bias torch.Size([3])
quant_conv.weight torch.Size([8, 8, 1, 1])
quant_conv.bias torch.Size([8])
post_quant_conv.weight torch.Size([4, 4, 1, 1])
post_quant_conv.bias torch.Size([4])